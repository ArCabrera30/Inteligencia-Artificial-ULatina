{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA y Preparaci√≥n ‚Äî Dataset de 2 Clases (Natalie Portman vs Scarlett Johansson)\n",
        "\n",
        "**Condici√≥n del curso:** Prohibido usar `scikit-learn`. Se utilizan **PyTorch, Torchvision, PIL, OpenCV, ImageHash, NumPy y Pandas**.\n",
        "\n",
        "Este cuaderno realiza:\n",
        "- Exploraci√≥n general del dataset (conteo por clase, resoluciones, formatos, im√°genes corruptas/vac√≠as, balance de clases).\n",
        "- An√°lisis estad√≠stico de color por canal RGB (media, desviaci√≥n), rangos globales y detecci√≥n de im√°genes at√≠picas (muy oscuras, borrosas).\n",
        "- Preprocesamiento b√°sico (redimensionado, normalizaci√≥n, conversi√≥n a tensores) con **Torchvision**.\n",
        "- Definici√≥n de **data augmentation** para robustecer el modelo (rotaciones, flips, cambios de color, etc.).\n",
        "- Detecci√≥n de **duplicados** mediante *perceptual hash*.\n",
        "- Divisi√≥n **estratificada** en train/val sin usar sklearn.\n",
        "- Exportaci√≥n de CSVs para control de calidad manual.\n",
        "\n",
        "### Estructura esperada de carpetas\n",
        "\n",
        "```\n",
        "data/\n",
        "  raw/\n",
        "    Natalie_Portman/\n",
        "    Scarlett_Johansson/\n",
        "```\n",
        "\n",
        "Si tus carpetas tienen otros nombres, ajusta el diccionario `CLASS_MAP` m√°s abajo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Instalaci√≥n de dependencias (solo se ejecuta autom√°ticamente en Colab)\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip -q install opencv-python imagehash tqdm matplotlib pillow pandas numpy torch torchvision --upgrade\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "print('‚úÖ Librer√≠as cargadas (sin scikit-learn)')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Configuraci√≥n de rutas y clases\n",
        "DATA_ROOT = Path('data/raw')  # ra√≠z donde viven las im√°genes crudas\n",
        "\n",
        "# Clases esperadas (puedes ajustar los nombres si tus carpetas son diferentes)\n",
        "CLASS_MAP = {\n",
        "    'Natalie_Portman': 0,\n",
        "    'Scarlett_Johansson': 1,\n",
        "}\n",
        "\n",
        "VALID_EXTS = {'.jpg', '.jpeg', '.png'}\n",
        "\n",
        "assert DATA_ROOT.exists(), '‚ùå No se encontr√≥ data/raw. Crea la estructura indicada y coloca las im√°genes.'\n",
        "print('üìÇ Ruta de datos:', DATA_ROOT.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Descubrimiento de im√°genes por clase\n",
        "records = []\n",
        "for cname, label in CLASS_MAP.items():\n",
        "    cdir = DATA_ROOT / cname\n",
        "    if not cdir.exists():\n",
        "        print(f'‚ö†Ô∏è Carpeta ausente: {cdir} ‚Äî se omitir√°')\n",
        "        continue\n",
        "    for p in cdir.rglob('*'):\n",
        "        if p.suffix.lower() in VALID_EXTS:\n",
        "            records.append({'path': str(p), 'class': cname, 'label': label})\n",
        "\n",
        "df = pd.DataFrame(records)\n",
        "print('Total de im√°genes encontradas:', len(df))\n",
        "display(df.head())\n",
        "assert len(df) > 0, '‚ùå No se encontraron im√°genes con extensiones v√°lidas (jpg/jpeg/png).'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Exploraci√≥n general: conteos, formatos, resoluciones, corruptas, balance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Conteo de im√°genes por clase\n",
        "conteo = df['class'].value_counts().rename_axis('clase').reset_index(name='imagenes')\n",
        "print('üìä Conteo por clase:')\n",
        "display(conteo)\n",
        "\n",
        "# Lectura de metadatos de cada imagen\n",
        "w_list, h_list, fmt_list, corrupt_flags = [], [], [], []\n",
        "for p in tqdm(df['path'], desc='Leyendo metadatos de im√°genes'):\n",
        "    try:\n",
        "        with Image.open(p) as im:\n",
        "            w, h = im.size\n",
        "            w_list.append(w)\n",
        "            h_list.append(h)\n",
        "            fmt_list.append(im.format)\n",
        "            corrupt_flags.append(False)\n",
        "    except Exception:\n",
        "        # Imagen da√±ada o ilegible\n",
        "        w_list.append(np.nan)\n",
        "        h_list.append(np.nan)\n",
        "        fmt_list.append('CORRUPT')\n",
        "        corrupt_flags.append(True)\n",
        "\n",
        "df['width'] = w_list\n",
        "df['height'] = h_list\n",
        "df['format'] = fmt_list\n",
        "df['is_corrupt'] = corrupt_flags\n",
        "\n",
        "print('üß® Im√°genes corruptas detectadas:', df['is_corrupt'].sum())\n",
        "print('\\nüìÅ Formatos encontrados:')\n",
        "display(df['format'].value_counts())\n",
        "\n",
        "# Histograma de tama√±os\n",
        "plt.figure()\n",
        "plt.hist(df['width'].dropna(), bins=30)\n",
        "plt.title('Distribuci√≥n de anchos de imagen')\n",
        "plt.xlabel('width (px)'); plt.ylabel('Frecuencia')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(df['height'].dropna(), bins=30)\n",
        "plt.title('Distribuci√≥n de altos de imagen')\n",
        "plt.xlabel('height (px)'); plt.ylabel('Frecuencia')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Estad√≠stica de color (RGB), rango global y detecci√≥n de im√°genes oscuras / borrosas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def image_stats_rgb(path):\n",
        "    \"\"\"Regresa mean RGB, std RGB, valor m√≠nimo y m√°ximo global de la imagen.\"\"\"\n",
        "    with Image.open(path) as im:\n",
        "        im = im.convert('RGB')\n",
        "        arr = np.array(im)\n",
        "        mean = arr.mean(axis=(0,1))      # [R,G,B]\n",
        "        std = arr.std(axis=(0,1))       # [R,G,B]\n",
        "        mn = arr.min()\n",
        "        mx = arr.max()\n",
        "    return mean, std, mn, mx\n",
        "\n",
        "def variance_of_laplacian(image_bgr):\n",
        "    \"\"\"Varianza del Laplaciano: medida de nitidez (baja => borrosa).\"\"\"\n",
        "    return cv2.Laplacian(image_bgr, cv2.CV_64F).var()\n",
        "\n",
        "rgb_mean, rgb_std, min_vals, max_vals, brightness, blurriness = [], [], [], [], [], []\n",
        "\n",
        "for p in tqdm(df['path'], desc='Calculando estad√≠sticas RGB / brillo / blur'):\n",
        "    try:\n",
        "        m, s, mn, mx = image_stats_rgb(p)\n",
        "        rgb_mean.append(m)\n",
        "        rgb_std.append(s)\n",
        "        min_vals.append(mn)\n",
        "        max_vals.append(mx)\n",
        "\n",
        "        # Brillo medio en escala de grises\n",
        "        with Image.open(p) as im:\n",
        "            im_gray = im.convert('L')\n",
        "            brightness.append(float(np.array(im_gray).mean()))\n",
        "\n",
        "        # Blur usando varianza de Laplaciano\n",
        "        img_bgr = cv2.imread(p)\n",
        "        if img_bgr is not None:\n",
        "            blurriness.append(float(variance_of_laplacian(img_bgr)))\n",
        "        else:\n",
        "            blurriness.append(np.nan)\n",
        "    except Exception:\n",
        "        rgb_mean.append([np.nan, np.nan, np.nan])\n",
        "        rgb_std.append([np.nan, np.nan, np.nan])\n",
        "        min_vals.append(np.nan)\n",
        "        max_vals.append(np.nan)\n",
        "        brightness.append(np.nan)\n",
        "        blurriness.append(np.nan)\n",
        "\n",
        "# A√±adimos columnas al dataframe\n",
        "df[['mean_R', 'mean_G', 'mean_B']] = pd.DataFrame(rgb_mean, index=df.index)\n",
        "df[['std_R', 'std_G', 'std_B']] = pd.DataFrame(rgb_std, index=df.index)\n",
        "df['min_val'] = min_vals\n",
        "df['max_val'] = max_vals\n",
        "df['brightness'] = brightness\n",
        "df['blurriness'] = blurriness\n",
        "\n",
        "print('üéØ Estad√≠sticas promedio por clase (RGB):')\n",
        "display(df[['class','mean_R','mean_G','mean_B','std_R','std_G','std_B']].groupby('class').mean())\n",
        "\n",
        "print('üåà Rango global de valores de pixel [min, max]:', int(df['min_val'].min()), int(df['max_val'].max()))\n",
        "\n",
        "# Definimos umbrales simples para marcar im√°genes oscuras y borrosas\n",
        "DARK_THR = 35   # brillo medio bajo => muy oscura\n",
        "BLUR_THR = 70   # varianza de Laplaciano baja => borrosa (ajustable)\n",
        "\n",
        "df['flag_dark'] = df['brightness'] < DARK_THR\n",
        "df['flag_blur'] = df['blurriness'] < BLUR_THR\n",
        "\n",
        "print('\\nüìå Proporci√≥n de im√°genes oscuras / borrosas por clase:')\n",
        "display(df.groupby('class')[['flag_dark','flag_blur']].mean())\n",
        "print('\\nTotal marcadas como oscuras:', int(df['flag_dark'].sum()))\n",
        "print('Total marcadas como borrosas:', int(df['flag_blur'].sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Detecci√≥n de duplicados por *perceptual hash* (pHash)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "hashes = []\n",
        "for p in tqdm(df['path'], desc='Calculando perceptual hash'):\n",
        "    try:\n",
        "        with Image.open(p) as im:\n",
        "            h = imagehash.phash(im.convert('RGB'))\n",
        "            hashes.append(str(h))\n",
        "    except Exception:\n",
        "        hashes.append('CORRUPT')\n",
        "\n",
        "df['phash'] = hashes\n",
        "\n",
        "# Agrupamos por hash para ver posibles duplicados\n",
        "dup_groups = df.groupby('phash').filter(lambda g: len(g) > 1).sort_values('phash')\n",
        "print('üîÅ Posibles duplicados detectados:', dup_groups.shape[0])\n",
        "display(dup_groups.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preprocesamiento y Aumento de Datos (Torchvision)\n",
        "\n",
        "Definimos dos pipelines de transformaciones:\n",
        "- `basic_tf`: para validaci√≥n/inferencia (solo resize + normalizaci√≥n).\n",
        "- `aug_tf`: para entrenamiento (incluye cambios de color, flips, rotaciones, recortes, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "IMG_SIZE = (224, 224)  # tama√±o cl√°sico para modelos tipo ResNet, etc.\n",
        "\n",
        "basic_tf = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "aug_tf = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=12),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0), ratio=(0.95, 1.05)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print('‚úÖ Transforms definidos (b√°sico y con data augmentation)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Divisi√≥n estratificada train/val sin sklearn\n",
        "\n",
        "Hacemos un split 80/20 manteniendo el balance entre clases usando solo NumPy y Pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def stratified_split(df, label_col='label', test_size=0.2, seed=42):\n",
        "    \"\"\"Divisi√≥n estratificada simple usando NumPy (sin sklearn).\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx_train, idx_val = [], []\n",
        "    for lbl, g in df.groupby(label_col):\n",
        "        ids = g.index.to_numpy()\n",
        "        rng.shuffle(ids)\n",
        "        n_val = int(len(ids) * test_size)\n",
        "        idx_val.extend(ids[:n_val])\n",
        "        idx_train.extend(ids[n_val:])\n",
        "    train_df = df.loc[idx_train].reset_index(drop=True)\n",
        "    val_df = df.loc[idx_val].reset_index(drop=True)\n",
        "    return train_df, val_df\n",
        "\n",
        "train_df, val_df = stratified_split(df, label_col='label', test_size=0.2, seed=42)\n",
        "\n",
        "print('Tama√±o TRAIN:', len(train_df))\n",
        "print('Tama√±o VAL  :', len(val_df))\n",
        "\n",
        "print('\\nDistribuci√≥n por clase en TRAIN:')\n",
        "display(train_df['class'].value_counts())\n",
        "print('\\nDistribuci√≥n por clase en VAL:')\n",
        "display(val_df['class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Exportaci√≥n de CSVs para control de calidad (QC)\n",
        "\n",
        "Se generan varios archivos en `data/qc/`:\n",
        "- `inventory_full.csv`: inventario completo con metadatos.\n",
        "- `train_list.csv` / `val_list.csv`: listas para cada split.\n",
        "- `to_review_flags.csv`: im√°genes oscuras, borrosas o corruptas.\n",
        "- `possible_duplicates.csv`: candidatos duplicados seg√∫n pHash.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "qc_path = Path('data/qc')\n",
        "qc_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "df.to_csv(qc_path / 'inventory_full.csv', index=False)\n",
        "train_df.to_csv(qc_path / 'train_list.csv', index=False)\n",
        "val_df.to_csv(qc_path / 'val_list.csv', index=False)\n",
        "\n",
        "flags_df = df[df['is_corrupt'] | df['flag_dark'] | df['flag_blur']]\n",
        "flags_df.to_csv(qc_path / 'to_review_flags.csv', index=False)\n",
        "\n",
        "dup_groups.to_csv(qc_path / 'possible_duplicates.csv', index=False)\n",
        "\n",
        "print('üíæ Archivos de control de calidad guardados en:', qc_path.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Dataset y DataLoaders de PyTorch (opcional para entrenamiento)\n",
        "\n",
        "A partir de `train_df` y `val_df` definimos un `Dataset` y `DataLoader` est√°ndar, listo para entrenar un modelo (por ejemplo, una `ResNet18`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class FaceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = Image.open(row['path']).convert('RGB')\n",
        "        x = self.transform(img)\n",
        "        y = int(row['label'])\n",
        "        return x, y\n",
        "\n",
        "train_ds = FaceDataset(train_df, aug_tf)\n",
        "val_ds = FaceDataset(val_df, basic_tf)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print('‚úÖ DataLoaders listos. Puedes usar train_loader y val_loader para entrenar tu modelo.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Checklist final de la tarea\n",
        "\n",
        "- [x] No se utiliz√≥ `scikit-learn`.\n",
        "- [x] Explorado el dataset: conteo, formatos, resoluciones, im√°genes corruptas.\n",
        "- [x] An√°lisis de color por canal RGB y rangos globales.\n",
        "- [x] Detecci√≥n de im√°genes oscuras y borrosas.\n",
        "- [x] Detecci√≥n de posibles duplicados (pHash).\n",
        "- [x] Definidas transformaciones b√°sicas y de aumento de datos.\n",
        "- [x] Divisi√≥n estratificada train/val (80/20) hecha manualmente.\n",
        "- [x] Exportados CSVs de control de calidad en `data/qc/`.\n",
        "- [x] Definidos `Dataset` y `DataLoader` de PyTorch listos para entrenamiento.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}