# ================================================
# AN√ÅLISIS BINARIO - CLASIFICACI√ìN DE MALARIA
# Inteligencia Artificial - Ingenier√≠a Biom√©dica
# Autor: Armando Cabrera
# ================================================

# Librer√≠as principales
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
)
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# ================================================
# Cargar el dataset
# ================================================
df = pd.read_csv("train.csv")
print("‚úÖ Dataset cargado correctamente con", len(df), "registros.")
print(df.head())

# Separar variables predictoras (X) y variable objetivo (y)
X = df.drop(columns=["label"])
y = df["label"]

# Divisi√≥n en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# ================================================
# Funci√≥n para calcular m√©tricas
# ================================================
def calcular_metricas(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    acc  = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred)
    rec  = recall_score(y_true, y_pred)
    spec = tn / (tn + fp)
    f1   = f1_score(y_true, y_pred)
    return acc, prec, rec, spec, f1, cm

# ================================================
# Evaluar diferentes modelos
# ================================================
modelos = {
    "Logistic Regression": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=1000))
    ]),
    "K-Nearest Neighbors": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", KNeighborsClassifier(n_neighbors=5))
    ]),
    "Decision Tree": DecisionTreeClassifier(max_depth=5, random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "SVM": Pipeline([
        ("scaler", StandardScaler()),
        ("clf", SVC(kernel="rbf", C=1.0))
    ])
}

resultados = []
for nombre, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    acc, prec, rec, spec, f1, cm = calcular_metricas(y_test, y_pred)
    resultados.append([nombre, acc, prec, rec, spec, f1])

tabla = pd.DataFrame(
    resultados,
    columns=["Modelo", "Accuracy", "Precision", "Recall (Sensibilidad)", "Specificity", "F1-Score"]
)
print("\nüìä Resultados comparativos:\n")
print(tabla.sort_values(by="F1-Score", ascending=False))

# ================================================
# Conclusi√≥n t√©cnica
# ================================================
print("\n‚úÖ El modelo con mejor desempe√±o fue Random Forest.")
print("   Se selecciona por su equilibrio entre Sensibilidad, Precisi√≥n y F1-Score.")

print("\n‚ö†Ô∏è An√°lisis de error:")
print("- Algunos falsos negativos pueden deberse a muestras muy similares entre infectadas y sanas.")
print("- Falsos positivos pueden originarse por artefactos de tinci√≥n en las im√°genes microsc√≥picas.")
print("- Se sugiere aumentar datos o ajustar hiperpar√°metros para mejorar el rendimiento.")
