{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tarea 2 — Regresión: Estimación del costo de seguro médico\n",
        "\n",
        "**Dataset recomendado:** [Medical Insurance Cost Dataset (Kaggle)](https://www.kaggle.com/datasets/mosapabdelghany/medical-insurance-cost-dataset)\n",
        "\n",
        "Este cuaderno cumple con los puntos solicitados:\n",
        "1. Crear repositorio (ya realizado) y preparar el análisis.\n",
        "2. Exploración de datos: descripción, valores vacíos y transformaciones iniciales.\n",
        "3. Análisis **univariante** de variables numéricas y categóricas, con interpretaciones.\n",
        "4. **Filtrado de outliers** por método IQR (intercuartiles) y justificación del corte.\n",
        "5. Definir si se **trata la variable objetivo** (`charges`) o se deja tal cual (se propone `log(charges)`).\n",
        "6. Análisis **bivariante**: gráfica de `charges` vs. cada variable y explicación.\n",
        "7. **Matriz de correlación** y decisión de eliminación de variables poco útiles.\n",
        "8. División del dataset en **train/test (80/20)** **estratificando** sobre cuantiles de `charges` para mantener la distribución.\n",
        "9. Guardar `train.csv` y `test.csv` para el modelado posterior.\n",
        "\n",
        "> **Nota**: Coloca el archivo original como `insurance.csv` en esta misma carpeta. Si no está presente, el cuaderno generará un conjunto **sintético** con las mismas columnas para que puedas practicar todo el flujo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 1) Carga de datos\n",
        "# ========================\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "path = Path('insurance.csv')\n",
        "if path.exists():\n",
        "    df = pd.read_csv(path)\n",
        "    origen = 'original Kaggle'\n",
        "else:\n",
        "    # Generador de datos sintéticos compatibles (solo para práctica)\n",
        "    np.random.seed(42)\n",
        "    n = 1338\n",
        "    df = pd.DataFrame({\n",
        "        'age': np.random.randint(18, 65, n),\n",
        "        'sex': np.random.choice(['male','female'], n),\n",
        "        'bmi': np.round(np.random.normal(30, 6, n), 2),\n",
        "        'children': np.random.randint(0, 5, n),\n",
        "        'smoker': np.random.choice(['yes','no'], n, p=[0.2,0.8]),\n",
        "        'region': np.random.choice(['southwest','southeast','northwest','northeast'], n),\n",
        "    })\n",
        "    # charges sintético: base + efectos aproximados\n",
        "    base = 2000 + df['age']*50 + (df['bmi']-25)*100 + df['children']*400\n",
        "    fum = np.where(df['smoker']=='yes', 12000, 0)\n",
        "    region_effect = df['region'].map({\n",
        "        'southwest': -200,\n",
        "        'southeast': 300,\n",
        "        'northwest': -100,\n",
        "        'northeast': 0\n",
        "    }).values\n",
        "    ruido = np.random.normal(0, 2000, n)\n",
        "    df['charges'] = np.maximum(1000, base + fum + region_effect + ruido)\n",
        "    origen = 'sintético (práctica)'\n",
        "\n",
        "print('Origen de los datos:', origen)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 2) Exploración inicial\n",
        "# ========================\n",
        "display(df.shape)\n",
        "display(df.dtypes)\n",
        "display(df.isna().sum())\n",
        "display(df.describe(include='all'))\n",
        "\n",
        "explicacion = (\n",
        "    \"Se revisan dimensiones, tipos de datos y valores faltantes. \"\n",
        "    \"En caso de NA, se aplicarán imputaciones (mediana para numéricas, moda para categóricas). \"\n",
        "    \"También se verifican rangos y consistencia de variables (por ejemplo, BMI, edad, etc.).\"\n",
        ")\n",
        "print(explicacion)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Tratamiento de NA (si los hubiera)\n",
        "for col in df.columns:\n",
        "    if df[col].dtype.kind in 'biufc':\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "    else:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Análisis univariante (numéricas y categóricas) con interpretaciones\n",
        "\n",
        "Se grafican histogramas para numéricas y barras para categóricas. Se incluyen comentarios sobre posibles sesgos o patrones.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_cols = ['age','bmi','children','charges']\n",
        "cat_cols = ['sex','smoker','region']\n",
        "\n",
        "for col in num_cols:\n",
        "    plt.figure()\n",
        "    plt.hist(df[col].values, bins=30)\n",
        "    plt.title(f'Distribución de {col}')\n",
        "    plt.xlabel(col); plt.ylabel('Frecuencia')\n",
        "    plt.show()\n",
        "\n",
        "for col in cat_cols:\n",
        "    plt.figure()\n",
        "    counts = df[col].value_counts()\n",
        "    plt.bar(counts.index.astype(str), counts.values)\n",
        "    plt.title(f'Distribución de {col}')\n",
        "    plt.xlabel(col); plt.ylabel('Conteo')\n",
        "    plt.xticks(rotation=20)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comentarios (ejemplo para tu reporte)\n",
        "- `smoker` suele estar altamente asociado a mayores `charges`.\n",
        "- `bmi` con colas derechas puede sugerir **outliers** en IMC muy altos.\n",
        "- Distribuciones por `region` pueden estar balanceadas o no, revisarlo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Filtrado de outliers por IQR (intercuartiles)\n",
        "\n",
        "Se aplica a numéricas: `age`, `bmi`, `children`, `charges`. Se justifica el corte en **Q1 - 1.5*IQR** y **Q3 + 1.5*IQR**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def iqr_filter(data, cols):\n",
        "    mask = pd.Series(True, index=data.index)\n",
        "    for c in cols:\n",
        "        q1, q3 = data[c].quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        low, high = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
        "        mask &= data[c].between(low, high)\n",
        "    return data[mask]\n",
        "\n",
        "cols_iqr = ['age','bmi','children','charges']\n",
        "df_filtered = iqr_filter(df, cols_iqr)\n",
        "print('Filtrado IQR: filas antes:', len(df), ' | después:', len(df_filtered))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) ¿Tratar la variable objetivo `charges`?\n",
        "Muchas veces `charges` presenta sesgo a la derecha. Se propone trabajar con `log_charges = log(charges)` para estabilizar varianza y mejorar linealidad. También conservamos `charges` original para comparar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "df_filtered = df_filtered.copy()\n",
        "df_filtered['log_charges'] = np.log(df_filtered['charges'])\n",
        "plt.figure(); plt.hist(df_filtered['charges'], bins=30); plt.title('charges (original)'); plt.show()\n",
        "plt.figure(); plt.hist(df_filtered['log_charges'], bins=30); plt.title('log(charges)'); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Análisis bivariante: `charges` vs. cada variable\n",
        "Se grafican relaciones simples. Para categóricas se usan promedios por grupo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Numéricas vs charges\n",
        "for col in ['age','bmi','children']:\n",
        "    plt.figure()\n",
        "    plt.scatter(df_filtered[col], df_filtered['charges'])\n",
        "    plt.title(f'{col} vs charges')\n",
        "    plt.xlabel(col); plt.ylabel('charges')\n",
        "    plt.show()\n",
        "\n",
        "# Categóricas: medias por grupo\n",
        "for col in ['sex','smoker','region']:\n",
        "    plt.figure()\n",
        "    means = df_filtered.groupby(col)['charges'].mean().sort_values()\n",
        "    plt.bar(means.index.astype(str), means.values)\n",
        "    plt.title(f'charges promedio por {col}')\n",
        "    plt.xticks(rotation=20)\n",
        "    plt.ylabel('charges promedio')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Matriz de correlación y selección de variables\n",
        "Se codifican variables categóricas para calcular correlaciones y decidir posibles eliminaciones por redundancia o baja relación.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df_enc = df_filtered.copy()\n",
        "df_enc['sex'] = (df_enc['sex']=='male').astype(int)\n",
        "df_enc['smoker'] = (df_enc['smoker']=='yes').astype(int)\n",
        "df_enc = pd.get_dummies(df_enc, columns=['region'], drop_first=True)\n",
        "corr = df_enc.corr(numeric_only=True)\n",
        "corr['charges'].sort_values(ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comentarios sugeridos\n",
        "- `smoker` suele ser la variable más correlacionada positivamente con `charges`.\n",
        "- `age` y `bmi` también aportan. `children` puede tener relación menor.\n",
        "- Si dos variables están muy correlacionadas entre sí, se puede descartar una para simplificar el modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) División en train/test (80/20) **estratificando** por cuantiles de `charges`\n",
        "Para mantener la distribución del objetivo en ambos conjuntos, se crean **bins** (cuantiles) de `charges` y se usa `StratifiedShuffleSplit` sobre esos bins.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "df_split = df_enc.copy()\n",
        "bins = pd.qcut(df_split['charges'], q=5, duplicates='drop')\n",
        "df_split['charges_bin'] = bins.cat.codes\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_idx, test_idx in split.split(df_split, df_split['charges_bin']):\n",
        "    train = df_split.iloc[train_idx].drop(columns=['charges_bin'])\n",
        "    test  = df_split.iloc[test_idx].drop(columns=['charges_bin'])\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "train.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Comprobar que proporciones de bins se mantienen aproximadamente\n",
        "def bin_props(frame):\n",
        "    b = pd.qcut(frame['charges'], q=5, duplicates='drop')\n",
        "    return b.value_counts(normalize=True).sort_index()\n",
        "\n",
        "print('Proporciones en TRAIN:\\n', bin_props(train))\n",
        "print('\\nProporciones en TEST:\\n', bin_props(test))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# 9) Guardar datasets para la fase de modelado\n",
        "train.to_csv('train.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)\n",
        "print('✅ Archivos guardados: train.csv y test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusión\n",
        "- Se realizó EDA completo, tratamiento de valores faltantes y outliers por IQR.\n",
        "- Se evaluó la variable objetivo (`charges`) y se propuso transformación logarítmica.\n",
        "- Se analizó la relación bivariante y la correlación para orientar selección de variables.\n",
        "- Se generaron `train.csv` y `test.csv` manteniendo la distribución del objetivo mediante estratificación por cuantiles.\n",
        "\n",
        "Este material está listo para la **fase de modelado de regresión** (por ejemplo, `LinearRegression`, `RandomForestRegressor`, `XGBRegressor`) en un cuaderno posterior.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}